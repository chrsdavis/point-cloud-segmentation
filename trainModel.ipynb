{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# lovasz softmax\n",
        "from lovasz_softmax import lovasz_softmax"
      ],
      "metadata": {
        "id": "3YEy8d8dDp28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "238922d3-58cd-4444-c51d-5ecd0086004b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'lovasz_softmax'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7ca1f7734a6e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# lovasz softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlovasz_softmax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlovasz_softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lovasz_softmax'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "save_path = None"
      ],
      "metadata": {
        "id": "VSL6o5IF5Lco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, baseDataset):\n",
        "    self.ds = baseDataset\n",
        "    self.transform = transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p = 0.5),\n",
        "    transforms.RandomApply([transforms.RandomRotation(degrees=10)], p = 0.5),\n",
        "    transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ds)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image, label = self.ds[idx]\n",
        "    image = Image.fromarray((image * 255).astype('uint8'))  # Assuming array is scaled [0, 1]\n",
        "    image = self.transform(image)\n",
        "    return image, label\n",
        "\n"
      ],
      "metadata": {
        "id": "r4z6als_RXh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vicha59CBq5I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class WeightedCrossEntropyLoss(torch.nn.Module):\n",
        "    def __init__(self, class_weights):\n",
        "        super().__init__()\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        return F.cross_entropy(outputs, targets, weight = self.class_weights)\n",
        "\n",
        "class CombinedLoss(torch.nn.Module):\n",
        "    def __init__(self, class_weights):\n",
        "        super().__init__()\n",
        "        self.wce_loss = WeightedCrossEntropyLoss(class_weights)\n",
        "        self.lovasz_loss = lovasz_softmax\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        loss_wce = self.wce_loss(inputs, targets)\n",
        "        loss_lovasz = self.lovasz_loss(outputs, targets)\n",
        "        return loss_wce + loss_lovasz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "save_path = None # TODO - set it as the name of the folder in Google Drive where you want to save all the model weights\n",
        "\n",
        "def train_model(model, train_loader, val_loader, class_weights, num_epochs, is_graph = True):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = SGD(model.parameters(), lr = 0.01, momentum= 0.9, weight_decay = 0.0001)\n",
        "    scheduler = StepLR(optimizer, 1, gamma = 0.01)\n",
        "\n",
        "    loss_fn = CombinedLoss(class_weights)\n",
        "    loss_values = []\n",
        "\n",
        "    train_acc_values, val_acc_values = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        correct_train, total_train = 0, 0\n",
        "        for inputs, targets, _, _ in train_loader:\n",
        "\n",
        "            # inputs -> B * 5 * H * W, targets: B * H * W\n",
        "\n",
        "            # targets[v, u] -> B\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)  # B * 20 * H * W\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "             # Calculate training accuracy\n",
        "            if is_graph:\n",
        "              _, predicted = torch.max(outputs, 1)\n",
        "              correct_train += (predicted == targets).sum().item()\n",
        "              total_train += targets.numel()\n",
        "\n",
        "        # Validation phase\n",
        "        if is_graph:\n",
        "          model.eval()\n",
        "          correct_val, total_val = 0, 0\n",
        "\n",
        "          with torch.no_grad():\n",
        "              for inputs, targets, _, _ in val_loader:\n",
        "                  inputs, targets = inputs.to(device), targets.to(device)\n",
        "                  outputs = model(inputs)\n",
        "                  _, predicted = torch.max(outputs, 1)\n",
        "                  correct_val += (predicted == targets).sum().item()\n",
        "                  total_val += targets.numel()\n",
        "\n",
        "          train_accuracy, val_accuracy = 100 * correct_val / total_val, 100 * correct_train / total_train\n",
        "\n",
        "          train_acc_values.append(train_accuracy)\n",
        "          val_acc_values.append(val_accuracy)\n",
        "\n",
        "          # saving weights every 10 epochs\n",
        "          if (epoch + 1) % 10 == 0:\n",
        "              torch.save(model.state_dict(), f'{save_path}/model_epoch_{epoch + 1}.pth')\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        epoch_loss = total_loss / len(train_loader)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if is_graph:\n",
        "            loss_values.append(epoch_loss)\n",
        "\n",
        "        print(f'Epoch {epoch + 1}, Loss: {epoch_loss}')\n",
        "\n",
        "    if is_graph:\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(range(1, num_epochs + 1), loss_values)\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Loss')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(range(1, num_epochs + 1), train_acc_values, label='Train')\n",
        "        plt.plot(range(1, num_epochs + 1), val_acc_values, label='Validation')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title('Training and Validation Accuracy')\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "xT6xrTdPD5GV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_weights(dataloader, num_classes = 20):\n",
        "    class_counts = {}\n",
        "\n",
        "    for _, labels in dataloader:\n",
        "        # assuming label is int\n",
        "        for label in labels:\n",
        "            class_counts[label] = class_counts.get(label, 0) + 1\n",
        "\n",
        "\n",
        "    class_frequencies = torch.zeros(num_classes)\n",
        "    for key, value in class_counts.items():\n",
        "        class_frequencies[key] = value\n",
        "\n",
        "    weights = 1.0 / torch.sqrt(class_frequencies)\n",
        "    weights[class_frequencies == 0] = 0\n",
        "\n",
        "    return weights\n"
      ],
      "metadata": {
        "id": "TYn2dbyEtGv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "trainset = None # TODO\n",
        "testset = None #TODO\n",
        "\n",
        "batch_size = 24\n",
        "\n",
        "# the purpose of the CustomDataset is to apply the random flips and rotations. If your dataset already takes that into account, you may not need to convert your dataset into CustomDataset format\n",
        "\n",
        "train_loader = DataLoader(CustomDataset(trainset), batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(CustomDataset(testset), batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "val_loader = DataLoader(CustomDataset(testset), batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "model = None # TODO: create model instance\n",
        "\n",
        "\n",
        "num_epochs = 10 # TODO: play with this hyperparameter\n",
        "class_weights = get_class_weights(train_loader)\n",
        "train_model(model, train_loader, val_loader, class_weights, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "Gh7EmvVGsM0c",
        "outputId": "c07a1cc9-7e05-460e-fa14-3326b0acaeb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6bff7ace619e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m train_loader = DataLoader(CustomDataset(trainset), batch_size=batch_size,\n\u001b[0m\u001b[1;32m      9\u001b[0m                                           shuffle=True, num_workers=2)\n\u001b[1;32m     10\u001b[0m testloader = DataLoader(CustomDataset(testset), batch_size=batch_size,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"replacement should be a boolean value, but got replacement={self.replacement}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36mnum_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;31m# dataset size might change at runtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-70bd3615d57e>\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    }
  ]
}